{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install Dependencies and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\sebas\\anaconda3\\envs\\web\\lib\\site-packages (2.19.0)\n",
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [44 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"C:\\Users\\sebas\\anaconda3\\envs\\Web\\Lib\\site-packages\\packaging\\requirements.py\", line 36, in __init__\n",
      "      parsed = _parse_requirement(requirement_string)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\sebas\\anaconda3\\envs\\Web\\Lib\\site-packages\\packaging\\_parser.py\", line 62, in parse_requirement\n",
      "      return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\sebas\\anaconda3\\envs\\Web\\Lib\\site-packages\\packaging\\_parser.py\", line 80, in _parse_requirement\n",
      "      url, specifier, marker = _parse_requirement_details(tokenizer)\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\sebas\\anaconda3\\envs\\Web\\Lib\\site-packages\\packaging\\_parser.py\", line 124, in _parse_requirement_details\n",
      "      marker = _parse_requirement_marker(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\sebas\\anaconda3\\envs\\Web\\Lib\\site-packages\\packaging\\_parser.py\", line 145, in _parse_requirement_marker\n",
      "      tokenizer.raise_syntax_error(\n",
      "    File \"C:\\Users\\sebas\\anaconda3\\envs\\Web\\Lib\\site-packages\\packaging\\_tokenizer.py\", line 167, in raise_syntax_error\n",
      "      raise ParserSyntaxError(\n",
      "  packaging._tokenizer.ParserSyntaxError: Expected end or semicolon (after name and no valid version specifier)\n",
      "      python_version>\"3.7\"\n",
      "                    ^\n",
      "  \n",
      "  The above exception was the direct cause of the following exception:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 35, in <module>\n",
      "    File \"C:\\Users\\sebas\\AppData\\Local\\Temp\\pip-install-wnz7u5h3\\tensorflow-gpu_ab54193864f743a78efb25eaab603c2a\\setup.py\", line 40, in <module>\n",
      "      setuptools.setup()\n",
      "    File \"C:\\Users\\sebas\\anaconda3\\envs\\Web\\Lib\\site-packages\\setuptools\\__init__.py\", line 116, in setup\n",
      "      _install_setup_requires(attrs)\n",
      "    File \"C:\\Users\\sebas\\anaconda3\\envs\\Web\\Lib\\site-packages\\setuptools\\__init__.py\", line 87, in _install_setup_requires\n",
      "      dist.parse_config_files(ignore_option_errors=True)\n",
      "    File \"C:\\Users\\sebas\\anaconda3\\envs\\Web\\Lib\\site-packages\\setuptools\\dist.py\", line 758, in parse_config_files\n",
      "      self._finalize_requires()\n",
      "    File \"C:\\Users\\sebas\\anaconda3\\envs\\Web\\Lib\\site-packages\\setuptools\\dist.py\", line 384, in _finalize_requires\n",
      "      self._normalize_requires()\n",
      "    File \"C:\\Users\\sebas\\anaconda3\\envs\\Web\\Lib\\site-packages\\setuptools\\dist.py\", line 402, in _normalize_requires\n",
      "      self.install_requires = list_(map(str, _reqs.parse(install_requires)))\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    File \"C:\\Users\\sebas\\anaconda3\\envs\\Web\\Lib\\site-packages\\packaging\\requirements.py\", line 38, in __init__\n",
      "      raise InvalidRequirement(str(e)) from e\n",
      "  packaging.requirements.InvalidRequirement: Expected end or semicolon (after name and no valid version specifier)\n",
      "      python_version>\"3.7\"\n",
      "                    ^\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tensorflow-gpu opencv-python matplotlib\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- -----------\n",
      "absl-py                   2.3.1\n",
      "anyio                     4.7.0\n",
      "argon2-cffi               21.3.0\n",
      "argon2-cffi-bindings      21.2.0\n",
      "asttokens                 3.0.0\n",
      "astunparse                1.6.3\n",
      "async-lru                 2.0.4\n",
      "attrs                     24.3.0\n",
      "babel                     2.16.0\n",
      "beautifulsoup4            4.12.3\n",
      "bleach                    6.2.0\n",
      "Bottleneck                1.4.2\n",
      "branca                    0.6.0\n",
      "Brotli                    1.0.9\n",
      "certifi                   2025.8.3\n",
      "cffi                      1.17.1\n",
      "charset-normalizer        3.3.2\n",
      "colorama                  0.4.6\n",
      "comm                      0.2.1\n",
      "contourpy                 1.3.1\n",
      "cycler                    0.11.0\n",
      "debugpy                   1.8.11\n",
      "decorator                 5.1.1\n",
      "defusedxml                0.7.1\n",
      "executing                 0.8.3\n",
      "fastjsonschema            2.20.0\n",
      "flatbuffers               25.2.10\n",
      "folium                    0.14.0\n",
      "fonttools                 4.55.3\n",
      "gast                      0.6.0\n",
      "geopandas                 1.0.1\n",
      "google-pasta              0.2.0\n",
      "graphviz                  0.20.1\n",
      "grpcio                    1.74.0\n",
      "h11                       0.14.0\n",
      "h5py                      3.14.0\n",
      "httpcore                  1.0.2\n",
      "httpx                     0.28.1\n",
      "idna                      3.7\n",
      "ipykernel                 6.29.5\n",
      "ipython                   9.1.0\n",
      "ipython_pygments_lexers   1.1.1\n",
      "ipywidgets                8.1.5\n",
      "jedi                      0.19.2\n",
      "Jinja2                    3.1.6\n",
      "joblib                    1.4.2\n",
      "json5                     0.9.25\n",
      "jsonschema                4.23.0\n",
      "jsonschema-specifications 2023.7.1\n",
      "jupyter_client            8.6.3\n",
      "jupyter_core              5.7.2\n",
      "jupyter-events            0.12.0\n",
      "jupyter-lsp               2.2.5\n",
      "jupyter_server            2.15.0\n",
      "jupyter_server_terminals  0.5.3\n",
      "jupyterlab                4.3.4\n",
      "jupyterlab_pygments       0.3.0\n",
      "jupyterlab_server         2.27.3\n",
      "jupyterlab_widgets        3.0.15\n",
      "keras                     3.11.1\n",
      "kiwisolver                1.4.8\n",
      "libclang                  18.1.1\n",
      "mapclassify               2.5.0\n",
      "Markdown                  3.8.2\n",
      "markdown-it-py            3.0.0\n",
      "MarkupSafe                3.0.2\n",
      "matplotlib                3.10.0\n",
      "matplotlib-inline         0.1.6\n",
      "mdurl                     0.1.2\n",
      "mistune                   3.1.2\n",
      "mkl_fft                   1.3.11\n",
      "mkl_random                1.2.8\n",
      "mkl-service               2.4.0\n",
      "ml_dtypes                 0.5.3\n",
      "namex                     0.1.0\n",
      "nbclient                  0.10.2\n",
      "nbconvert                 7.16.6\n",
      "nbformat                  5.10.4\n",
      "nest-asyncio              1.6.0\n",
      "networkx                  3.4.2\n",
      "notebook                  7.3.2\n",
      "notebook_shim             0.2.4\n",
      "numexpr                   2.10.1\n",
      "numpy                     1.26.4\n",
      "opencv-python             4.8.1.78\n",
      "opt_einsum                3.4.0\n",
      "optree                    0.17.0\n",
      "outcome                   1.3.0.post0\n",
      "overrides                 7.4.0\n",
      "packaging                 24.2\n",
      "pandas                    2.2.3\n",
      "pandocfilters             1.5.0\n",
      "parso                     0.8.4\n",
      "pillow                    11.1.0\n",
      "pip                       25.1\n",
      "platformdirs              4.3.7\n",
      "prometheus_client         0.21.1\n",
      "prompt-toolkit            3.0.43\n",
      "protobuf                  5.29.5\n",
      "psutil                    5.9.0\n",
      "pure-eval                 0.2.2\n",
      "pycparser                 2.21\n",
      "pydot                     4.0.1\n",
      "Pygments                  2.19.1\n",
      "pyogrio                   0.10.0\n",
      "pyparsing                 3.2.0\n",
      "pyproj                    3.6.1\n",
      "PySocks                   1.7.1\n",
      "python-dateutil           2.9.0.post0\n",
      "python-json-logger        3.2.1\n",
      "pytz                      2024.1\n",
      "pywin32                   308\n",
      "pywinpty                  2.0.15\n",
      "PyYAML                    6.0.2\n",
      "pyzmq                     26.2.0\n",
      "referencing               0.30.2\n",
      "requests                  2.32.3\n",
      "rfc3339-validator         0.1.4\n",
      "rfc3986-validator         0.1.1\n",
      "rich                      14.1.0\n",
      "rpds-py                   0.22.3\n",
      "scikit-learn              1.6.1\n",
      "scipy                     1.15.3\n",
      "seaborn                   0.13.2\n",
      "selenium                  4.32.0\n",
      "Send2Trash                1.8.2\n",
      "setuptools                78.1.1\n",
      "shapely                   2.0.6\n",
      "six                       1.17.0\n",
      "sniffio                   1.3.0\n",
      "sortedcontainers          2.4.0\n",
      "soupsieve                 2.5\n",
      "stack-data                0.2.0\n",
      "tensorboard               2.19.0\n",
      "tensorboard-data-server   0.7.2\n",
      "tensorflow                2.19.0\n",
      "termcolor                 3.1.0\n",
      "terminado                 0.17.1\n",
      "threadpoolctl             3.5.0\n",
      "tinycss2                  1.4.0\n",
      "tornado                   6.4.2\n",
      "tqdm                      4.67.1\n",
      "traitlets                 5.14.3\n",
      "trio                      0.30.0\n",
      "trio-websocket            0.12.2\n",
      "typing_extensions         4.12.2\n",
      "tzdata                    2025.2\n",
      "unicodedata2              15.1.0\n",
      "urllib3                   2.3.0\n",
      "wcwidth                   0.2.5\n",
      "webencodings              0.5.1\n",
      "websocket-client          1.8.0\n",
      "Werkzeug                  3.1.3\n",
      "wheel                     0.45.1\n",
      "widgetsnbextension        4.0.13\n",
      "win-inet-pton             1.1.0\n",
      "wrapt                     1.17.2\n",
      "wsproto                   1.2.0\n",
      "xyzservices               2022.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Remove dodgy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebas\\AppData\\Local\\Temp\\ipykernel_46028\\4232469594.py:2: DeprecationWarning: 'imghdr' is deprecated and slated for removal in Python 3.13\n",
      "  import imghdr\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'C:/Users/sebas/OneDrive/Desktop/ProyectoIA/UTKFace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exts = ['.jpeg','.jpg', '.bmp', '.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, _, files in os.walk(data_dir):\n",
    "    for fname in files:\n",
    "        image_path = Path(root) / fname\n",
    "        if image_path.suffix.lower() not in image_exts:\n",
    "            print(f\"Extensión no permitida: {image_path}\")\n",
    "            # image_path.unlink()  # si quieres borrar\n",
    "            continue\n",
    "        img = cv2.imread(str(image_path))\n",
    "        if img is None:\n",
    "            print(f\"No se pudo leer con OpenCV: {image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 files belonging to 0 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No images found in directory C:/Users/sebas/OneDrive/Desktop/ProyectoIA/UTKFace. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m data = tf.keras.utils.image_dataset_from_directory(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33mC:/Users/sebas/OneDrive/Desktop/ProyectoIA/UTKFace\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\Web\\Lib\\site-packages\\keras\\src\\utils\\image_dataset_utils.py:329\u001b[39m, in \u001b[36mimage_dataset_from_directory\u001b[39m\u001b[34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[39m\n\u001b[32m    325\u001b[39m image_paths, labels = dataset_utils.get_training_or_validation_split(\n\u001b[32m    326\u001b[39m     image_paths, labels, validation_split, subset\n\u001b[32m    327\u001b[39m )\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m image_paths:\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    330\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo images found in directory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    331\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAllowed formats: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mALLOWLIST_FORMATS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    332\u001b[39m     )\n\u001b[32m    334\u001b[39m dataset = paths_and_labels_to_dataset(\n\u001b[32m    335\u001b[39m     image_paths=image_paths,\n\u001b[32m    336\u001b[39m     image_size=image_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m    347\u001b[39m     seed=seed,\n\u001b[32m    348\u001b[39m )\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: No images found in directory C:/Users/sebas/OneDrive/Desktop/ProyectoIA/UTKFace. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
     ]
    }
   ],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory(r'C:/Users/sebas/OneDrive/Desktop/ProyectoIA/UTKFace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x,y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.7)\n",
    "val_size = int(len(data)*.2)\n",
    "test_size = int(len(data)*.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Build Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pre.result(), re.result(), acc.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('29_0_1_20170115235536036.jpg.chip')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.image.resize(img, (256,256))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if yhat > 0.5: \n",
    "    print(f'Predicted class is Sad')\n",
    "else:\n",
    "    print(f'Predicted class is Happy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('models','imageclassifier.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model('imageclassifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.predict(np.expand_dims(resize/255, 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
